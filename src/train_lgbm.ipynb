{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32170c93-6e55-47f3-a745-a7b59242da52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zrway/anaconda3/envs/env_FastIntra/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 11.0.0. Please consider upgrading.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from types import SimpleNamespace\n",
    "import time\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0770979b-1bd3-4869-9c2b-22211de9d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BasicFeatures = [\n",
    "    'QTD', 'BTD', 'TTD', 'MTTD', 'QTMTD',\n",
    "    'currIntraMode', \n",
    "    'mrlIdx', 'ispMode', 'mtsFlag', 'lfnstIdx', 'mipFlag', 'mipTransposedFlag',  # \n",
    "    'isModeVer', 'intraPredAngleMode',  # \n",
    "    'currIntraFracBits', 'currIntraDistortion', 'currIntraCost',  # \n",
    "    'bestPredModeDCT2', \n",
    "    'mean', 'stddev', 'diffStdDevVer', 'diffStdDevHor', 'Gx', 'Gy', 'ratioGxGy', 'normGradient',  # \n",
    "    'entropy', 'skewness', 'kurtosis', 'pixelSum',  # \n",
    "    \n",
    "    'BH_Above_mean', 'BH_Above_stddev', 'BH_Above_Gx', 'BH_Above_Gy', 'BH_Above_ratioGxGy', 'BH_Above_normGradient', \n",
    "    'BH_Below_mean', 'BH_Below_stddev', 'BH_Below_Gx', 'BH_Below_Gy', 'BH_Below_ratioGxGy', 'BH_Below_normGradient', \n",
    "    'BV_Left_mean', 'BV_Left_stddev', 'BV_Left_Gx', 'BV_Left_Gy', 'BV_Left_ratioGxGy', 'BV_Left_normGradient', \n",
    "    'BV_Right_mean', 'BV_Right_stddev', 'BV_Right_Gx', 'BV_Right_Gy', 'BV_Right_ratioGxGy', 'BV_Right_normGradient', \n",
    "    'TH_Above_mean', 'TH_Above_stddev', 'TH_Above_Gx', 'TH_Above_Gy', 'TH_Above_ratioGxGy', 'TH_Above_normGradient',\n",
    "    'TH_Middle_mean', 'TH_Middle_stddev', 'TH_Middle_Gx', 'TH_Middle_Gy', 'TH_Middle_ratioGxGy', 'TH_Middle_normGradient', \n",
    "    'TH_Below_mean', 'TH_Below_stddev', 'TH_Below_Gx', 'TH_Below_Gy', 'TH_Below_ratioGxGy', 'TH_Below_normGradient', \n",
    "    'TV_Left_mean', 'TV_Left_stddev', 'TV_Left_Gx', 'TV_Left_Gy', 'TV_Left_ratioGxGy', 'TV_Left_normGradient',\n",
    "    'TV_Middle_mean', 'TV_Middle_stddev', 'TV_Middle_Gx', 'TV_Middle_Gy', 'TV_Middle_ratioGxGy', 'TV_Middle_normGradient',\n",
    "    'TV_Right_mean', 'TV_Right_stddev', 'TV_Right_Gx', 'TV_Right_Gy', 'TV_Right_ratioGxGy', 'TV_Right_normGradient', \n",
    "    \n",
    "    'neighAvgQT', 'neighHigherQT', 'neighAvgMTT', 'neighHigherMTT', 'neighAvgHorNum', 'neighAvgVerNum',  # \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "825e8449-f3e4-490b-ba6d-3b14ca83af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将array-like 的class_weights 转换为字典\n",
    "def convert_class_weight(class_weights):\n",
    "    n_classes = len(class_weights)\n",
    "    result = dict()\n",
    "    for i in range(n_classes):\n",
    "        result[i] = class_weights[i]\n",
    "    return result\n",
    "\n",
    "# 标签转换，将[0, 2, 3, 4, 5] 转换为 [0, 1, 2, 3, 4]\n",
    "def convert_label(df: pd.DataFrame, shape: str, use_down_sample=False):\n",
    "    df['label'] = df['splitMode']\n",
    "    if shape in ['32x16', '16x32']:\n",
    "        df.loc[df['splitMode'] != 0, 'label'] -= 1\n",
    "    elif shape == '32x8' or shape == '16x8':  # 无模式 1、4\n",
    "        df.loc[df['splitMode'].isin([2, 3]), 'label'] -= 1\n",
    "        df.loc[df['splitMode'] == 5, 'label'] -= 2\n",
    "    elif shape == '8x32' or shape == '8x16':  # 无模式 1、5\n",
    "        df.loc[df['splitMode'] != 0, 'label'] -= 1\n",
    "    elif shape == '16x16': # 去除QT模式的样本,  and \n",
    "        df = df.loc[df['splitMode'] != 1]\n",
    "        df.loc[df['splitMode'] != 0, 'label'] -= 1\n",
    "    elif shape == '8x8':  # 无模式 1, 4, 5\n",
    "        df = df.loc[df['splitMode'] != 1]\n",
    "        df.loc[df['splitMode'] != 0, 'label'] -= 1\n",
    "        \n",
    "    return df\n",
    "\n",
    "# 读取 parquet 版本的数据\n",
    "def load_data_v3(store_dir: str, qp: str, shape: str, val_ratio=0.1):\n",
    "    store_path = os.path.join(store_dir, shape, f'QP{qp}_{shape}.parquet.gzip')\n",
    "    df = pd.read_parquet(store_path)\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    y = df['label']\n",
    "    X = df[BasicFeatures]\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=val_ratio, shuffle=True, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "\n",
    "# LGBM 模型训练\n",
    "def train(pkl_dir: str, qp: str, shape: str, params: SimpleNamespace, class_weight: dict, save_model: bool, save_dir: str, early_stop_rounds=20, use_down_sample=False):\n",
    "    # 加载数据\n",
    "    X_train, X_test, y_train, y_test = load_data_v3(pkl_dir, qp, shape)\n",
    "\n",
    "    # 获取权重\n",
    "    train_class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "    train_class_weights = convert_class_weight(train_class_weights)\n",
    "    print(train_class_weights)\n",
    "\n",
    "    # 构造模型\n",
    "    lgb_classifier = lgb.LGBMClassifier(\n",
    "        boosting_type='gbdt',\n",
    "        num_leaves=params.num_leaves,\n",
    "        max_depth=params.max_depth,\n",
    "        learning_rate=params.learning_rate,\n",
    "        n_estimators=params.n_estimators,\n",
    "        objective='multiclass',\n",
    "        class_weight=train_class_weights,\n",
    "        subsample=params.subsample,\n",
    "        subsample_freq=params.subsample_freq,\n",
    "        num_threads=36,\n",
    "    )\n",
    "    # 拟合数据\n",
    "    lgb_classifier.fit(\n",
    "        X=X_train, \n",
    "        y=y_train, \n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric='multi_error',\n",
    "        callbacks=[lgb.early_stopping(early_stop_rounds)]  # 早停机制\n",
    "    )\n",
    "    # 计算指标\n",
    "    y_score = lgb_classifier.predict_proba(X_test)\n",
    "    y_pred = y_score.argmax(axis=1)\n",
    "    report = metrics.classification_report(y_pred=y_pred, y_true=y_test, digits=4)\n",
    "    top2_accuracy = metrics.top_k_accuracy_score(y_score=y_score, y_true=y_test, k=2)  # labels=[0, 1, 2, 3, 4, 5]\n",
    "    print(f\"Top2 Accuracy: {top2_accuracy}\\nClassification_repost:\\n{report}\")\n",
    "    # 存储模型\n",
    "    if save_model:\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        save_path = os.path.join(save_dir, f\"QP{qp}_{shape}.txt\")\n",
    "        lgb_classifier.booster_.save_model(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9dd07b-da6c-45ea-8d75-1e45c29bb0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training model: QP37_32x32 ....\n",
      "{0: 0.46459204719751657, 1: 0.8777857451937937, 2: 0.8214249353269748, 3: 1.3019441225226283, 4: 2.1126084576107784, 5: 4.007750231434442}\n"
     ]
    }
   ],
   "source": [
    "params = SimpleNamespace()\n",
    "params.num_leaves = 95\n",
    "params.max_depth = -1\n",
    "params.learning_rate = 0.1  # \n",
    "params.n_estimators = 10000\n",
    "params.subsample = 0.9\n",
    "params.subsample_freq = 50\n",
    "params.early_stop_rounds = 5\n",
    "\n",
    "pkl_dir = \"parquets_lgbm\"\n",
    "save_dir = \"scripts/lgbm_scripts\"\n",
    "save_dir = os.path.join(save_dir, '0107-0')  # time.strftime('%m%d')\n",
    "\n",
    "QPs = ['37', '32', '27', '22']  # '37', '32', '27', '22'\n",
    "Shapes = ['32x32', '32x16', '16x32', '8x32', '32x8', '16x16']  # '32x32', '32x16', '16x32', '8x32', '32x8', '16x16', '8x16', '16x8', '8x8'\n",
    "\n",
    "for shape in Shapes:\n",
    "    for qp in QPs:\n",
    "        # load_data(pkl_dir, qp, shape)\n",
    "        print(f\"Starting training model: QP{qp}_{shape} ....\")\n",
    "        class_weight = dict()  # get_class_weight(qp, shape, class_weights)\n",
    "\n",
    "        train(\n",
    "            pkl_dir=pkl_dir,\n",
    "            qp=qp,\n",
    "            shape=shape,\n",
    "            params=params,\n",
    "            class_weight=class_weight,\n",
    "            save_model=True,\n",
    "            save_dir=save_dir,\n",
    "            early_stop_rounds=params.early_stop_rounds,\n",
    "            use_down_sample=False,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
